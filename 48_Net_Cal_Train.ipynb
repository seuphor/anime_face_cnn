{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils import save \n",
    "import numpy as np\n",
    "from models._48_net import calib_48Net\n",
    "from utils.utilities import batch_selection\n",
    "import sys\n",
    "from utils.params import *\n",
    "import time\n",
    "from utils.utilities import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 300\n",
    "lr = [5e-3, 1e-3, 5e-4, 1e-4, 1e-5]\n",
    "bias_init = [0.0]\n",
    "reg = [0.0, 1e-4]\n",
    "_48_calib_batch = batch_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from D:\\programing project\\python project\\trying stuffpickle/\n"
     ]
    }
   ],
   "source": [
    "result_list = save.loader('calibrate_db_48_test.txt')\n",
    "valid_input = np.concatenate([result_list[i][0][np.newaxis] for i in range(len(result_list))])\n",
    "valid_target = np.asarray([result_list[i][1] for i in range(len(result_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from D:\\programing project\\python project\\trying stuffpickle/\n"
     ]
    }
   ],
   "source": [
    "calibrate_db_48 = save.loader('calibrate_db_48_long.txt')\n",
    "calibrate_db_48 = calibrate_db_48[:int(len(calibrate_db_48) / batch_size) * batch_size]\n",
    "inputs_calib_48 = np.zeros((len(calibrate_db_48), 48, 48, 3))\n",
    "targets_calib_48 = np.zeros((len(calibrate_db_48), 45), dtype=np.int32)\n",
    "\n",
    "for i in range(len(calibrate_db_48)):\n",
    "    inputs_calib_48[i,:] = calibrate_db_48[i][0]\n",
    "    targets_calib_48[i,calibrate_db_48[i][1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bat_len = int(len(inputs_calib_48) / batch_size)\n",
    "total_iters = bat_len * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_correct_percentage(pred, truth, top_numb=3):\n",
    "    assert(truth.shape[0] == pred.shape[0])\n",
    "    top_score = [arr.argsort()[-top_numb:][::-1] for arr in pred]\n",
    "    score_list = [1 if truth[i] in top_score[i] else 0 for i in range(truth.shape[0])]\n",
    "    percentage = np.sum(score_list) / truth.shape[0]\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_48 = np.zeros((batch_size, p_net_48, p_net_48, 3))\n",
    "target_48 = np.zeros((batch_size, 45))\n",
    "pickle_path = 'saver/calib_48/mean_var/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10641/23400  Loss: 0.00102/0.401888  CRT_Top1/Top3: 74.11% / 86.11%  Max_Top1/Top3: 74.11% / 86.11%  Max_Epo: 137  Bad_cnt: 0"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-1236cbdbed1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     }\n\u001b[0;32m---> 71\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcal_48_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                     \u001b[0msingle_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcal_48_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \"\"\"\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3727\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3728\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3729\u001b[0;31m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for r in reg:\n",
    "    for b in bias_init:\n",
    "        for l in lr:\n",
    "            record_l = l\n",
    "            correct_pnt_top3 = 0\n",
    "            correct_pnt_top1 = 0\n",
    "            max_pnt_top3 = 0\n",
    "            max_pnt_top1 = 0\n",
    "            bad_cnt = 0\n",
    "            max_epo = 0\n",
    "            \n",
    "            g = tf.Graph()\n",
    "            with g.as_default():\n",
    "                input_48_cal = tf.placeholder(tf.float32, [None,48,48,3])\n",
    "                target_48_cal = tf.placeholder(tf.float32, [None,45])\n",
    "                keep_prob = tf.placeholder(tf.float32)\n",
    "                cal_48_net = calib_48Net(input_48_cal, target_48_cal, keep_prob, lr=l, bias_init=b, reg=r)\n",
    "            \n",
    "            sess = tf.InteractiveSession(config=tf.ConfigProto(\n",
    "                allow_soft_placement=True, log_device_placement=True), graph=g)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            for epo in range(epochs):\n",
    "                loss = 0\n",
    "                \n",
    "                feed_valid = {\n",
    "                    input_48_cal:valid_input,\n",
    "                    keep_prob:1.0\n",
    "                }\n",
    "                pred_target = cal_48_net.prediction.eval(feed_valid)\n",
    "\n",
    "                correct_pnt_top3 = valid_correct_percentage(pred_target, valid_target, 3)\n",
    "                correct_pnt_top1 = valid_correct_percentage(pred_target, valid_target, 1)\n",
    "                \n",
    "                if correct_pnt_top1 > max_pnt_top1 and epo != 0:\n",
    "                    max_pnt_top1 = correct_pnt_top1\n",
    "                    max_pnt_top3 = correct_pnt_top3\n",
    "                    bad_cnt = 0\n",
    "                    max_epo = epo + 1\n",
    "                    saver = tf.train.Saver()\n",
    "                    saver.save(sess, p_model_dir + 'calib_48/max/_Net48_b{}_lr{}_reg{}.ckpt'.format(b,record_l,r))\n",
    "                    with open(pickle_path + '_Net48_MV_b={}_lr={}_reg={}.txt'.format(b, record_l, r), 'wb') as f:\n",
    "                            pickle.dump(mean_var_list, f)\n",
    "                            f.close()\n",
    "                else:\n",
    "                    bad_cnt += 1\n",
    "                \n",
    "                if bad_cnt % 4 == 0:\n",
    "                    l = l * .98\n",
    "                    \n",
    "                mean_var_list = np.zeros((4,64))\n",
    "                \n",
    "                if bad_cnt >= 30:\n",
    "                    break\n",
    "\n",
    "                for bat in range(bat_len):\n",
    "                    iters = epo * bat_len + bat\n",
    "                    input_48, target_48 = _48_calib_batch.next_batch(inputs_calib_48, targets_calib_48, batch_size)\n",
    "\n",
    "                    feed_train = {\n",
    "                        input_48_cal:input_48,\n",
    "                        target_48_cal:target_48,\n",
    "                        keep_prob:.5\n",
    "                    }\n",
    "\n",
    "                    feed_out = {\n",
    "                        input_48_cal:input_48,\n",
    "                        target_48_cal:target_48,\n",
    "                        keep_prob:1.0\n",
    "                    }\n",
    "                    loss += cal_48_net.loss.eval(feed_out)\n",
    "                    single_loss = cal_48_net.loss.eval(feed_out)\n",
    "                    \n",
    "                    cal_48_net.train_step.run(feed_train)\n",
    "                    \n",
    "                    mean_var_list[0,:] += cal_48_net.mean_conv1.eval(feed_out)\n",
    "                    mean_var_list[1,:] += cal_48_net.var_conv1.eval(feed_out)\n",
    "                    mean_var_list[2,:] += cal_48_net.mean_conv2.eval(feed_out)\n",
    "                    mean_var_list[3,:] += cal_48_net.var_conv2.eval(feed_out)\n",
    "\n",
    "                    sys.stdout.write('\\rIteration: ' + str(iters+1) + '/' + str(total_iters) + \\\n",
    "                                     '  Loss: ' + str(loss/(iters+1))[:7] + '/' + str(single_loss) + \\\n",
    "                                     '  CRT_Top1/Top3: ' + str(correct_pnt_top1*100)[:5] + '% / ' + str(correct_pnt_top3*100)[:5] + '%' + \\\n",
    "                                     '  Max_Top1/Top3: ' + str(max_pnt_top1*100)[:5] + '% / ' + str(max_pnt_top3*100)[:5] + '%' + \\\n",
    "                                     '  Max_Epo: ' + str(max_epo) + '  Bad_cnt: ' + str(bad_cnt))\n",
    "                mean_var_list = mean_var_list / bat_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_TOP1/TOP3:2.11111% / 5.66666%\n",
      "Iteration: 77/780    Loss: 2.54377Accuracy_TOP1/TOP3:36.5555% / 60.4444%\n",
      "Iteration: 155/780    Loss: 1.55908Accuracy_TOP1/TOP3:57.0% / 80.6666%\n",
      "Iteration: 233/780    Loss: 1.19756Accuracy_TOP1/TOP3:61.5555% / 83.6666%\n",
      "Iteration: 311/780    Loss: 0.943508Accuracy_TOP1/TOP3:65.0% / 87.4444%\n",
      "Iteration: 389/780    Loss: 0.767564Accuracy_TOP1/TOP3:69.4444% / 88.6666%\n",
      "Iteration: 467/780    Loss: 0.687124Accuracy_TOP1/TOP3:72.2222% / 89.6666%\n",
      "Iteration: 545/780    Loss: 0.65522Accuracy_TOP1/TOP3:71.8888% / 88.6666%\n",
      "Iteration: 623/780    Loss: 0.461942Accuracy_TOP1/TOP3:71.4444% / 88.7777%\n",
      "Iteration: 701/780    Loss: 0.505466Accuracy_TOP1/TOP3:73.0% / 89.6666%\n",
      "Iteration: 779/780    Loss: 0.339889"
     ]
    }
   ],
   "source": [
    "for epo in range(epochs):\n",
    "    \n",
    "    feed_valid = {\n",
    "        input_48_cal:valid_input,\n",
    "        keep_prob:1.0\n",
    "    }\n",
    "    pred_target = cal_48_net.prediction.eval(feed_valid)\n",
    "    \n",
    "    correct_pnt_top3 = valid_correct_percentage(pred_target, valid_target, 3)\n",
    "    correct_pnt_top1 = valid_correct_percentage(pred_target, valid_target, 1)\n",
    "    \n",
    "    print('Accuracy_TOP1/TOP3:{}% / {}%'.format(str(correct_pnt_top1*100)[:7], str(correct_pnt_top3*100)[:7]))\n",
    "    # print(_48_calib_batch.current_index)\n",
    "    for bat in range(bat_len):\n",
    "        iters = epo * bat_len + bat\n",
    "        input_48, target_48 = _48_calib_batch.next_batch(inputs_calib_48, targets_calib_48, batch_size)\n",
    "        \n",
    "        feed_train = {\n",
    "            input_48_cal:input_48,\n",
    "            target_48_cal:target_48,\n",
    "            keep_prob:.5\n",
    "        }\n",
    "        \n",
    "        feed_out = {\n",
    "            input_48_cal:input_48,\n",
    "            target_48_cal:target_48,\n",
    "            keep_prob:1.0\n",
    "        }\n",
    "        loss = cal_48_net.loss.eval(feed_out)\n",
    "        cal_48_net.train_step.run(feed_train)\n",
    "        \n",
    "        sys.stdout.write('\\rIteration: ' + str(iters) + '/' + str(total_iters) + '    Loss: ' + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 48, 48, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
