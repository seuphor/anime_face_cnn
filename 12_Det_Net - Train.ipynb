{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from models._12_net import detect_12Net\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from utils.utilities import batch_selection\n",
    "from utils.sampling import GetSample\n",
    "from utils import save\n",
    "import numpy as np\n",
    "from utils.params import *\n",
    "import sys\n",
    "from utils.cnn_utils import *\n",
    "from utils.utilities import *\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from D:\\programing project\\python project\\trying stuffpickle/\n",
      "Loaded from D:\\programing project\\python project\\trying stuffpickle/\n"
     ]
    }
   ],
   "source": [
    "pos_db_12 = save.loader('pos_db_12.txt')\n",
    "neg_db_12 = save.loader('neg_db_12.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    input_12_node = tf.placeholder(tf.float32, [None,12,12,3])\n",
    "    target_12_node = tf.placeholder(tf.float32, [None,1])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    net_12 = detect_12Net(input_12_node, target_12_node, keep_prob, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=tf.ConfigProto(\n",
    "  allow_soft_placement=True, log_device_placement=True), graph=g)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# train_writer = tf.summary.FileWriter('./logs/train/Det_12', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dir = 'Test_source/test/'\n",
    "test_face = 'Test_source/test_face/'\n",
    "test_img = ['41009506_p1.jpg', '32819641_p0.jpg', '2015-02-08-709570.jpg', '46255545_p0.jpg', '42435403_p0.jpg']\n",
    "\n",
    "\n",
    "face_list = [face_crop_scale(test_face + path) for path in test_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = [5e-2, 1e-2, 5e-3, 1e-3, 5e-4]\n",
    "bias_init = [0.00]\n",
    "pepochs = 500\n",
    "neg_db_12 = neg_db_12[:10080*2,:]\n",
    "#neg_db_12 = neg_db_12[:10080,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Bias_init:0.0   Learning_rate:0.05   epo:500\n",
      "Epoch:500     loss/single_loss:0.0731/0.0843756     iteration:34999/35000     Bad_CNT:8903     Bad_ratio: 1271.85714%                      Right Detect Ratio: [0 2 1 5 1]     Suggested_total: [31  5 17 13 14]     Max_detect: [0 3 2 3 0]        Now_ratio: 0.182973497091     Max_ratio: 0.253333333333       Max_suggested: [18  5 12  6  5]     Bad_det: 77    L:0.008115528676075822   Max_epo: 114\n",
      "\n",
      "**Bias_init:0.0   Learning_rate:0.01   epo:500\n",
      "Epoch:110     loss/single_loss:0.0310/0.0201437     iteration:7683/35000     Bad_CNT:9080     Bad_ratio: 1327.48538%                      Right Detect Ratio: [ 9  8  4 10 12]     Suggested_total: [359 108  84 152 117]     Max_detect: [ 9  8  4 10 12]        Now_ratio: 0.0630232671649     Max_ratio: 0.0630232671649       Max_suggested: [359 108  84 152 117]     Bad_det: 0    L:0.006676079717550942   Max_epo: 109"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-de905d743321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mbad_cnt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mnet_12\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \"\"\"if iter_index % 100 == 0:\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \"\"\"\n\u001b[0;32m-> 1550\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3762\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3764\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#total_iteration = p_epochs * int(neg_db_12.shape[0] / p_neg_batch)\n",
    "bat_len = int(neg_db_12.shape[0] / p_neg_batch)\n",
    "bad_cnt = 0\n",
    "single_loss = 0\n",
    "max_epo = 0\n",
    "suggested_number = 200.0\n",
    "\n",
    "\n",
    "for b in bias_init:\n",
    "    for l in lr:\n",
    "        record_l = l\n",
    "        total_iteration = pepochs * int(neg_db_12.shape[0] / p_neg_batch)\n",
    "        print('**Bias_init:{}   Learning_rate:{}   epo:{}'.format(b,l,pepochs))\n",
    "        batch_sel_pos = batch_selection()\n",
    "        batch_sel_neg = batch_selection()\n",
    "        cur_score_list = [-0.1 for _ in range(5)]\n",
    "        pre_det = [0 for _ in range(5)]\n",
    "        max_score_list = [0.0 for _ in range(5)]\n",
    "        suggest_amount = [0 for _ in range(5)]\n",
    "        max_ratio = [0 for _ in range(5)]\n",
    "        max_print = [0 for _ in range(5)]\n",
    "        max_de = np.asarray([0 for _ in range(5)])\n",
    "        max_sug = np.asarray([0 for _ in range(5)])\n",
    "        max_avg = 0.0\n",
    "        avg_avg = 0.0\n",
    "        ch_ratio = np.zeros(5)\n",
    "        bad_det = 0\n",
    "        inputs = np.zeros((p_batch_size, 12, 12, 3))\n",
    "        targets = np.zeros((p_batch_size, 1))\n",
    "\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            input_12_node = tf.placeholder(tf.float32, [None,None,None,3])\n",
    "            target_12_node = tf.placeholder(tf.float32, [None,1])\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            learning_rate = tf.placeholder(tf.float32)\n",
    "            net_12 = detect_12Net(input_12_node, target_12_node, keep_prob, learning_rate)\n",
    "\n",
    "        sess = tf.InteractiveSession(config=tf.ConfigProto(\n",
    "          allow_soft_placement=True, log_device_placement=True), graph=g)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        #train_writer = tf.summary.FileWriter('./logs/train/Det_12/lr={},b={},ep={},GS'.format(lr,b,pepochs), sess.graph)\n",
    "        for epo in range(pepochs):\n",
    "            batch_sel_pos = batch_selection()\n",
    "            batch_sel_neg = batch_selection()\n",
    "            \n",
    "            loss = 0\n",
    "            if (epo + 1) % 5 == 0:\n",
    "                \n",
    "                #pre_det = cur_det\n",
    "                cur_det = [detection_windows(img_scalar(test_dir + t_img), \n",
    "                                            p_net_12, net_12, input_12_node, \n",
    "                                            keep_prob, thres=.8) for t_img in test_img]\n",
    "                suggest_amount = np.asarray([len(result_box) for result_box in cur_det])\n",
    "                cur_score_list = np.asarray([len(det_box_eval(face_list[i], cur_det[i])) \n",
    "                                  if det_box_eval(face_list[i], cur_det[i]).any() else 0 for i in range(len(test_img))])\n",
    "                list_ratio = [cur_score_list[i] / suggest_amount[i] for i in range(5)]\n",
    "                avg_avg = np.average(cur_score_list / suggest_amount)\n",
    "                #ch_ratio = np.array(cur_det) / (np.array(pre_det) + 1e-9)\n",
    "                if max_avg <= avg_avg:\n",
    "                    max_avg = avg_avg\n",
    "                    max_sug = suggest_amount\n",
    "                    max_ratio = list_ratio\n",
    "                    max_de = cur_score_list\n",
    "                    bad_det = 0\n",
    "                    saver = tf.train.Saver()\n",
    "                    saver.save(sess, p_model_dir + 'det_12/max/12_net_Adam_,lr={}b={}Trying.ckpt'.format(record_l,b))\n",
    "                    max_epo = epo\n",
    "                else:\n",
    "                    bad_det += 1\n",
    "                \n",
    "            if (bad_det+1) % 5 == 0:\n",
    "                l = l * .98\n",
    "            if bad_det >= 100:\n",
    "                print(' Breaking\\n')\n",
    "                break\n",
    "            \n",
    "            for i in range(bat_len):\n",
    "                iter_index = epo*int(neg_db_12.shape[0] / p_neg_batch) + i\n",
    "                inputs[:p_pos_batch,] = batch_sel_pos.next_batch_single(pos_db_12, p_pos_batch)\n",
    "                inputs[p_pos_batch:,] = batch_sel_neg.next_batch_single(neg_db_12, p_neg_batch)\n",
    "                targets[:p_pos_batch,] = np.ones((p_pos_batch,1))\n",
    "                targets[p_pos_batch:,] = np.zeros((p_neg_batch,1))\n",
    "\n",
    "                feed_regular = {\n",
    "                    input_12_node: inputs,\n",
    "                    target_12_node: targets,\n",
    "                    keep_prob:1.0,\n",
    "                    learning_rate:l\n",
    "                }\n",
    "                feed_train = {\n",
    "                    input_12_node: inputs,\n",
    "                    target_12_node: targets,\n",
    "                    keep_prob:.5,\n",
    "                    learning_rate:l\n",
    "                }\n",
    "\n",
    "                loss += net_12.loss.eval(feed_regular)\n",
    "                single_loss = net_12.loss.eval(feed_regular)\n",
    "\n",
    "                if single_loss > 0.1:\n",
    "                    bad_cnt += 1\n",
    "                \n",
    "                net_12.train_step.run(feed_train)\n",
    "\n",
    "                \"\"\"if iter_index % 100 == 0:\n",
    "                    summary = net_12.merged.eval(feed_regular)\n",
    "                    train_writer.add_summary(summary, iter_index)\"\"\"\n",
    "\n",
    "                sys.stdout.write('\\rEpoch:' + str(epo+1) + \\\n",
    "                                 '     loss/single_loss:' + str(loss / (i+1))[:6] + '/' + str(single_loss)[:10] + \\\n",
    "                                 '     iteration:' + str(iter_index) + '/' + str(total_iteration) + \\\n",
    "                                 '     Bad_CNT:' + str(bad_cnt) + \\\n",
    "                                 '     Bad_ratio: ' + str(100*float(bad_cnt)/((iter_index%(10 * bat_len))+1))[:10] + \"%\" + \\\n",
    "                                 '                      Right Detect Ratio: ' + str(cur_score_list) + \\\n",
    "                                 '     Suggested_total: ' + str(suggest_amount) + \\\n",
    "                                 '     Max_detect: ' + str(max_de) + '        Now_ratio: ' + str(avg_avg) + \\\n",
    "                                 '     Max_ratio: ' + str(max_avg) + '       Max_suggested: ' + str(max_sug) + \\\n",
    "                                 '     Bad_det: ' + str(bad_det) + '    L:' + str(l) + '   Max_epo: ' + str(max_epo))\n",
    "\n",
    "        print('\\n')\n",
    "        # '     Avg_score:' + str(np.sum(max_score_list)/len(test_img)) + \\\n",
    "        # return xmin, ymin, xmax, ymax, confidence score, img_crop obj, scale\n",
    "        \n",
    "        \n",
    "        #for t_img in test_img:\n",
    "            #detec_wins = detection_windows(img_scalar(test_dir + t_img), p_net_12, net_12, input_12_node, keep_prob, thres=0.1)\n",
    "            #list_det.append(len(detec_wins))\n",
    "        #print('Detection numbers: \\n', list_det)\n",
    "        #saver = tf.train.Saver()\n",
    "        #saver.save(sess, p_model_dir + 'det_12/12_net_AdaDelta_l={},b={},iter={}.ckpt'.format(l,b,iter_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2349, 2367,  814, 2462, 1882]), array([21, 15, 11, 20, 23]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_amount, cur_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0098270283757586948"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(cur_score_list / suggest_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011026046349365892"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(max_de / max_sug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2801, 1901,  945, 2205, 1645]), array([25, 17, 13, 21, 23]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sug, max_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0078338174456473904"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([19, 17, 16, 19, 18]) / np.sum([4062, 1853, 2504, 1656, 1286]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.00963', '0.01064', '0.01248', '0.00982', '0.01421']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"{0:.5f}\".format(l) for l in lll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples Checked..\n",
      "IMG_INDEX:112/112\n",
      "Finished\n",
      "Saved in D:\\programing project\\python project\\trying stuffpickle/\n"
     ]
    }
   ],
   "source": [
    "Get = GetSample()\n",
    "pos_db_12 = Get.get_pos_img(12)\n",
    "save.saver('pos_db_12.txt', pos_db_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from D:\\programing project\\python project\\trying stuffpickle/\n"
     ]
    }
   ],
   "source": [
    "Get = GetSample()\n",
    "pos_db_12 = save.loader('pos_db_12.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 12, 12, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_db_12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_sel_pos = batch_selection()\n",
    "batch_sel_neg = batch_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = np.zeros((p_batch_size, 12, 12, 3))\n",
    "targets = np.zeros((p_batch_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    input_12_node = tf.placeholder(tf.float32, [None,12,12,3])\n",
    "    target_12_node = tf.placeholder(tf.float32, [None,1])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    net_12 = detect_12Net(input_12_node, target_12_node, keep_prob, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=tf.ConfigProto(\n",
    "  allow_soft_placement=True, log_device_placement=True), graph=g)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# train_writer = tf.summary.FileWriter('./logs/train/Det_12', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_db_12 = Get.get_neg_img(12)\n",
    "total_iteration = p_epochs * int(neg_db_12.shape[0] / p_neg_batch)\n",
    "bat_len = int(neg_db_12.shape[0] / p_neg_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dir = 'Test_source/test/'\n",
    "test_face = 'Test_source/test_face/'\n",
    "test_img = ['41009506_p1.jpg', '32819641_p0.jpg', '2015-02-08-709570.jpg', '46255545_p0.jpg', '42435403_p0.jpg']\n",
    "\n",
    "\n",
    "face_list = [face_crop_scale(test_face + path) for path in test_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = [1e-1, 8e-2, 5e-2, 1e-2, 8e-3]\n",
    "bias_init = [0.00]\n",
    "pepochs = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = [1e-4]\n",
    "bias_init = [0.00]\n",
    "pepochs = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Bias_init:0.0   Learning_rate:0.1   epo:800\n",
      "Epoch:569     loss/single_loss:0.0815/0.0817171     iteration:6827/9600     Bad_CNT:2     Bad_ratio: 1.85185185%                      Right Detect Ratio: [0.025, 0.06, 0.05, 0.045, 0.065]     Max_Detect: [0.025, 0.06, 0.065, 0.04, 0.065]     Avg_ratio: 0.051     Bad_det: 23    L:0.018869332916279676   Max_epo: 329 Breaking\n",
      "\n",
      "\n",
      "\n",
      "**Bias_init:0.0   Learning_rate:0.08   epo:800\n",
      "Epoch:499     loss/single_loss:0.1297/0.129896     iteration:5987/9600     Bad_CNT:120     Bad_ratio: 111.111111%                      Right Detect Ratio: [0, 0.06, 0.035, 0.035, 0.05]     Max_Detect: [0, 0.065, 0.04, 0.03, 0.05]     Avg_ratio: 0.037     Bad_det: 23    L:0.006557296286187064   Max_epo: 259 Breaking\n",
      "\n",
      "\n",
      "\n",
      "**Bias_init:0.0   Learning_rate:0.05   epo:800\n",
      "Epoch:509     loss/single_loss:0.1093/0.0979574     iteration:6107/9600     Bad_CNT:103     Bad_ratio: 95.3703703%                      Right Detect Ratio: [0.02, 0.065, 0.04, 0.04, 0.06]     Max_Detect: [0.015, 0.07, 0.045, 0.04, 0.055]     Avg_ratio: 0.045     Bad_det: 23    L:0.009434666458139838   Max_epo: 269 Breaking\n",
      "\n",
      "\n",
      "\n",
      "**Bias_init:0.0   Learning_rate:0.01   epo:800\n",
      "Epoch:249     loss/single_loss:0.5157/0.518438     iteration:2987/9600     Bad_CNT:120     Bad_ratio: 111.111111%                      Right Detect Ratio: [0, 0.02, 0, 0, 0]     Max_Detect: [0, 0, 0.025, 0, 0]     Avg_ratio: 0.005     Bad_det: 23    L:0.0018869332916279671   Max_epo: 9 Breaking\n",
      "\n",
      "\n",
      "\n",
      "**Bias_init:0.0   Learning_rate:0.008   epo:800\n",
      "Epoch:249     loss/single_loss:0.4961/0.489133     iteration:2987/9600     Bad_CNT:120     Bad_ratio: 111.111111%                      Right Detect Ratio: [0, 0.04, 0.01, 0, 0]     Max_Detect: [0.01, 0.01, 0.035, 0.005, 0.03]     Avg_ratio: 0.018     Bad_det: 23    L:0.0015095466333023735   Max_epo: 9 Breaking\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg_db_12 = Get.get_neg_img(12)\n",
    "#total_iteration = p_epochs * int(neg_db_12.shape[0] / p_neg_batch)\n",
    "bat_len = int(neg_db_12.shape[0] / p_neg_batch)\n",
    "bad_cnt = 0\n",
    "single_loss = 0\n",
    "max_epo = 0\n",
    "suggested_number = 200.0\n",
    "\n",
    "for l in lr:\n",
    "    for b in bias_init:\n",
    "        record_l = l\n",
    "        total_iteration = pepochs * int(neg_db_12.shape[0] / p_neg_batch)\n",
    "        print('**Bias_init:{}   Learning_rate:{}   epo:{}'.format(b,l,pepochs))\n",
    "        batch_sel_pos = batch_selection()\n",
    "        batch_sel_neg = batch_selection()\n",
    "        cur_score_list = [-0.1 for _ in range(5)]\n",
    "        pre_det = [0 for _ in range(5)]\n",
    "        max_score_list = [0.0 for _ in range(5)]\n",
    "        ch_ratio = np.zeros(5)\n",
    "        bad_det = 0\n",
    "        inputs = np.zeros((p_batch_size, 12, 12, 3))\n",
    "        targets = np.zeros((p_batch_size, 1))\n",
    "\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            input_12_node = tf.placeholder(tf.float32, [None,None,None,3])\n",
    "            target_12_node = tf.placeholder(tf.float32, [None,1])\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            learning_rate = tf.placeholder(tf.float32)\n",
    "            net_12 = detect_12Net(input_12_node, target_12_node, keep_prob, learning_rate)\n",
    "\n",
    "        sess = tf.InteractiveSession(config=tf.ConfigProto(\n",
    "          allow_soft_placement=True, log_device_placement=True), graph=g)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        #train_writer = tf.summary.FileWriter('./logs/train/Det_12/lr={},b={},ep={},GS'.format(lr,b,pepochs), sess.graph)\n",
    "        for epo in range(pepochs):\n",
    "            batch_sel_pos = batch_selection()\n",
    "            batch_sel_neg = batch_selection()\n",
    "            #if (epo + 1) == 200:\n",
    "                #l = 6e-2\n",
    "            # Recreate the neg_sample every 10th epoch\n",
    "            \"\"\"if (np.sum(np.asarray(min_det)<100) >= 1) and (l>5e-4):\n",
    "                l = 5e-3\"\"\"\n",
    "                \n",
    "            if (epo + 1) % 10 == 0:\n",
    "                #if bad_cnt < (0.1 * bat_len * 10):\n",
    "                neg_db_12 = Get.get_neg_img(12)\n",
    "                bad_cnt = 0\n",
    "                #else: \n",
    "                #bad_cnt = 0\n",
    "            loss = 0\n",
    "            if (epo + 1) % 10 == 0:\n",
    "                \n",
    "                #pre_det = cur_det\n",
    "                cur_det = [detection_windows_ver2(img_scalar(test_dir + t_img), \n",
    "                                            p_net_12, net_12, input_12_node, \n",
    "                                            keep_prob) for t_img in test_img]\n",
    "                \n",
    "                cur_score_list = [len(det_box_eval(face_list[i], cur_det[i])) / suggested_number \n",
    "                                  if det_box_eval(face_list[i], cur_det[i]).any() else 0 for i in range(len(test_img))] \n",
    "                #ch_ratio = np.array(cur_det) / (np.array(pre_det) + 1e-9)\n",
    "                if np.sum(max_score_list) < np.sum(cur_score_list):\n",
    "                    max_score_list = cur_score_list\n",
    "                    bad_det = 0\n",
    "                    saver = tf.train.Saver()\n",
    "                    saver.save(sess, p_model_dir + 'det_12/max/12_net_AdaDelta_,lr={}b={}Trying.ckpt'.format(record_l,b))\n",
    "                    max_epo = epo\n",
    "                else:\n",
    "                    bad_det += 1\n",
    "                #if (np.sum(ch_ratio>.98)) >= 2:\n",
    "                    #bad_det += 1\n",
    "                #else:\n",
    "                    #bad_det = 0\n",
    "                \n",
    "            if (bad_det+1) % 10 == 0:\n",
    "                l = l * .92\n",
    "            if bad_det >= 24:\n",
    "                print(' Breaking\\n')\n",
    "                break\n",
    "            \n",
    "            for i in range(bat_len):\n",
    "                iter_index = epo*int(neg_db_12.shape[0] / p_neg_batch) + i\n",
    "                inputs[:p_pos_batch,] = batch_sel_pos.next_batch_single(pos_db_12, p_pos_batch)\n",
    "                inputs[p_pos_batch:,] = batch_sel_neg.next_batch_single(neg_db_12, p_neg_batch)\n",
    "                targets[:p_pos_batch,] = np.ones((p_pos_batch,1))\n",
    "                targets[p_pos_batch:,] = np.zeros((p_neg_batch,1))\n",
    "\n",
    "                feed_regular = {\n",
    "                    input_12_node: inputs,\n",
    "                    target_12_node: targets,\n",
    "                    keep_prob:1.0,\n",
    "                    learning_rate:l\n",
    "                }\n",
    "                feed_train = {\n",
    "                    input_12_node: inputs,\n",
    "                    target_12_node: targets,\n",
    "                    keep_prob:.65,\n",
    "                    learning_rate:l\n",
    "                }\n",
    "\n",
    "                loss += net_12.loss.eval(feed_regular)\n",
    "                single_loss = net_12.loss.eval(feed_regular)\n",
    "\n",
    "                if single_loss > 0.1:\n",
    "                    bad_cnt += 1\n",
    "                \n",
    "                net_12.train_step.run(feed_train)\n",
    "\n",
    "                \"\"\"if iter_index % 100 == 0:\n",
    "                    summary = net_12.merged.eval(feed_regular)\n",
    "                    train_writer.add_summary(summary, iter_index)\"\"\"\n",
    "\n",
    "                sys.stdout.write('\\rEpoch:' + str(epo+1) + \\\n",
    "                                 '     loss/single_loss:' + str(loss / (i+1))[:6] + '/' + str(single_loss)[:10] + \\\n",
    "                                 '     iteration:' + str(iter_index) + '/' + str(total_iteration) + \\\n",
    "                                 '     Bad_CNT:' + str(bad_cnt) + \\\n",
    "                                 '     Bad_ratio: ' + str(100*float(bad_cnt)/((iter_index%(10 * bat_len))+1))[:10] + \"%\" + \\\n",
    "                                 '                      Right Detect Ratio: ' + str(cur_score_list) + \\\n",
    "                                 '     Max_Detect: ' + str(max_score_list) + \\\n",
    "                                 '     Avg_ratio: ' + str(np.sum(max_score_list)/len(test_img)) + \\\n",
    "                                 '     Bad_det: ' + str(bad_det) + '    L:' + str(l) + '   Max_epo: ' + str(max_epo))\n",
    "\n",
    "        print('\\n')\n",
    "        # '     Avg_score:' + str(np.sum(max_score_list)/len(test_img)) + \\\n",
    "        # return xmin, ymin, xmax, ymax, confidence score, img_crop obj, scale\n",
    "        \n",
    "        \n",
    "        #for t_img in test_img:\n",
    "            #detec_wins = detection_windows(img_scalar(test_dir + t_img), p_net_12, net_12, input_12_node, keep_prob, thres=0.1)\n",
    "            #list_det.append(len(detec_wins))\n",
    "        #print('Detection numbers: \\n', list_det)\n",
    "        #saver = tf.train.Saver()\n",
    "        #saver.save(sess, p_model_dir + 'det_12/12_net_AdaDelta_l={},b={},iter={}.ckpt'.format(l,b,iter_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.train.RMSPropOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = [1509, 111, 192, 2087, 906]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_arr = np.asarray(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(list_arr<200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dir = 'Test_source/test/'\n",
    "test_img = '41009506_p1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return xmin, ymin, xmax, ymax, confidence score, img_crop obj, scale\n",
    "detec_wins = detection_windows(img_scalar(test_dir + test_img), p_net_12, net_12, input_12_node, keep_prob, thres=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12843"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detec_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw = img_scalar(test_dir + test_img)\n",
    "for win in detec_wins:\n",
    "    ImageDraw.Draw(draw).rectangle(list(np.asarray(win[:4],dtype=np.int32)), outline='red')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
